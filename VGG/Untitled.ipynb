{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_op(input_op,name,kh,kw,n_out,dh,dw,p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\",\n",
    "                                shape=[kh,kw,n_in,n_out],dtype=tf.float32,\n",
    "                                initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv = tf.nn.conv2d(input_op,kernel,(1,dh,dw,1),padding='SAME')\n",
    "        bias_init_val=tf.constant(0.0,shape=[n_out],dtype=tf.float32)\n",
    "        biases = tf.Variable(bias_init_val,trainable=True,name='b')\n",
    "        z=tf.nn.bias_add(conv,biases)\n",
    "        activation=tf.nn.relu(z,name=scope)\n",
    "        p+=[kernel,biases]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_op(input_op,name,n_out,p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\",\n",
    "                                shape = [n_in,n_out],dtype=tf.float32,\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(0.1,shape=[n_out],dtype=tf.float32),name='b')\n",
    "        activation=tf.nn.relu_layer(input_op,kernel,biases,name=scope)\n",
    "        p+=[kernel,biases]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mpool_op(input_op,name,kh,kw,dh,dw):\n",
    "    return tf.nn.max_pool(input_op,\n",
    "                         ksize=[1,kh,kw,1],\n",
    "                         strides=[1,dh,dw,1],\n",
    "                         padding='SAME',\n",
    "                         name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_op(input_op,keep_prob):\n",
    "    p=[]\n",
    "    conv1_1 =conv_op(input_op,name=\"conv1_1\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
    "    conv1_2 =conv_op(conv1_1,name=\"conv1_2\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
    "    pool1=mpool_op(conv1_2,name=\"pool1\",kh=2,kw=2,dw=2,dh=2)\n",
    "    conv2_1 = conv_op(pool1,name=\"conv2_1\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
    "    conv2_2=conv_op(conv2_1,name=\"conv2_2\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
    "    pool2=mpool_op(conv2_2,name=\"pool2\",kh=2,kw=2,dh=2,dw=2)\n",
    "    conv3_1=conv_op(pool2,name=\"conv3_1\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    conv3_2=conv_op(conv3_1,name=\"conv3_2\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    conv3_3=conv_op(conv3_2,name=\"conv3_3\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    pool3=mpool_op(conv3_3,name=\"pool3\",kh=2,kw=2,dh=2,dw=2)\n",
    "    conv4_1=conv_op(pool3,name=\"conv4_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv4_2=conv_op(conv4_1,name=\"conv4_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv4_3=conv_op(conv4_2,name=\"conv4_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    pool4=mpool_op(conv4_3,name=\"pool4\",kh=2,kw=2,dh=2,dw=2)\n",
    "    conv5_1=conv_op(pool4,name=\"conv5_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv5_2=conv_op(conv5_1,name=\"conv5_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv5_3=conv_op(conv5_2,name=\"conv5_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    pool5=mpool_op(conv5_3,name=\"pool5\",kh=2,kw=2,dh=2,dw=2)\n",
    "    shp=pool5.get_shape()\n",
    "    flattened_shape=shp[1].value*shp[2].value*shp[3].value\n",
    "    resh1=tf.reshape(pool5,[-1,flattened_shape],name='resh1')\n",
    "    fc6=fc_op(resh1,name=\"fc6\",n_out=4096,p=p)\n",
    "    fc6_drop=tf.nn.dropout(fc6,keep_prob,name=\"fc6_drop\")\n",
    "    fc7=fc_op(fc6_drop,name=\"fc7\",n_out=4096,p=p)\n",
    "    fc7_drop=tf.nn.dropout(fc7,keep_prob,name=\"fc7_drop\")\n",
    "    fc8=fc_op(fc7_drop,name=\"fc8\",n_out=1000,p=p)\n",
    "    softmax=tf.nn.softmax(fc8)\n",
    "    predictions=tf.argmax(softmax,1)\n",
    "    return predictions,softmax,fc8,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session,target,feed,info_string):\n",
    "    num_steps_burn_in = 10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    for i in range(num_batches+num_steps_burn_in):\n",
    "        start_time = time.time()\n",
    "        _ = session.run(target , feed_dict = feed)\n",
    "        duration = time.time() - start_time\n",
    "        if i >= num_steps_burn_in:\n",
    "            if not i % 10 :\n",
    "                print('%s : step %d , duration =%.3f' %\n",
    "                     (datetime.now(),i-num_steps_burn_in,duration))\n",
    "                total_duration += duration\n",
    "                total_duration_squared += duration * duration\n",
    "    mn = total_duration / num_batches\n",
    "    vr  =total_duration_squared/num_batches-mn*mn\n",
    "    sd = math.sqrt(vr)\n",
    "    print('%s :%s across %d steps, %.3f +/- %.3f sec /batch'% \n",
    "          (datetime.now(),info_string,num_batches,mn,sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size,\n",
    "                                              image_size,\n",
    "                                              image_size,3],\n",
    "                                             dtype=tf.float32,\n",
    "                                             stddev=1e-1))\n",
    "        keep_prob  =tf.placeholder(tf.float32)\n",
    "        predictions,softmax,fc8,p = inference_op(images,keep_prob)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        time_tensorflow_run(sess,predictions,{keep_prob:1.0},\"Forward\")\n",
    "        objective = tf.nn.l2_loss(fc8)\n",
    "        grad = tf.gradients(objective,p)\n",
    "        time_tensorflow_run(sess,grad,{keep_prob:0.5},\"Forward-backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-09 16:51:12.841747 : step 0 , duration =0.533\n",
      "2017-09-09 16:51:18.175683 : step 10 , duration =0.534\n",
      "2017-09-09 16:51:23.506901 : step 20 , duration =0.534\n",
      "2017-09-09 16:51:28.840081 : step 30 , duration =0.534\n",
      "2017-09-09 16:51:34.174721 : step 40 , duration =0.534\n",
      "2017-09-09 16:51:39.507022 : step 50 , duration =0.534\n",
      "2017-09-09 16:51:44.840989 : step 60 , duration =0.534\n",
      "2017-09-09 16:51:50.175142 : step 70 , duration =0.533\n",
      "2017-09-09 16:51:55.508856 : step 80 , duration =0.533\n",
      "2017-09-09 16:52:00.843861 : step 90 , duration =0.533\n",
      "2017-09-09 16:52:05.645740 :Forward across 100 steps, 0.053 +/- 0.160 sec /batch\n",
      "2017-09-09 16:52:31.464807 : step 0 , duration =1.874\n",
      "2017-09-09 16:52:50.432222 : step 10 , duration =1.869\n",
      "2017-09-09 16:53:09.372008 : step 20 , duration =1.899\n",
      "2017-09-09 16:53:28.394984 : step 30 , duration =1.922\n",
      "2017-09-09 16:53:47.294841 : step 40 , duration =1.883\n",
      "2017-09-09 16:54:06.260981 : step 50 , duration =1.893\n",
      "2017-09-09 16:54:25.097743 : step 60 , duration =1.867\n",
      "2017-09-09 16:54:44.057025 : step 70 , duration =1.897\n",
      "2017-09-09 16:55:02.864346 : step 80 , duration =1.869\n",
      "2017-09-09 16:55:21.802783 : step 90 , duration =1.970\n",
      "2017-09-09 16:55:38.892580 :Forward-backward across 100 steps, 0.189 +/- 0.568 sec /batch\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_batches = 100\n",
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
